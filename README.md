# ğŸ’¬ AI Chat

A modular AI chat application powered by open-source and cloud LLMs, with a Streamlit interface, FastAPI backend, and a LangGraph agent that can search the web autonomously.

## Features

- **Multi-model support** â€” Switch between local models (Phi-3, Gemma 2B, Mistral, GPT-4 Turbo, Qwen3 4B) and cloud models (Groq Llama 3.1, Mixtral, GPT-OSS 120B)
- **Tool-augmented agent** â€” LangGraph ReAct agent with DuckDuckGo web search â€” the model decides when to search
- **FastAPI backend** â€” REST API with interactive docs at `/docs`
- **Adjustable temperature** â€” Control response creativity with a slider (0.0â€“1.0)
- **Custom system prompts** â€” Set the assistant's personality per session
- **Multi-turn conversations** â€” Full chat history maintained during session
- **Structured logging** â€” Console + rotating file logs, env-configurable
- **100% local option** â€” All LLM inference can run on your machine via Ollama

## Architecture

```
Streamlit UI â”€â”€HTTPâ”€â”€â–¶ FastAPI API â”€â”€â–¶ Chat Service â”€â”€â–¶ LangGraph Agent
                                                            â”‚
                                                      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                                                 Tool Calls    LLM Calls
                                                 (DuckDuckGo)  (Local / Groq)
```

| Layer | Package | Key Modules |
|-------|---------|-------------|
| UI | `src/ui/` | `chat.py` â€” Streamlit chat interface |
| API | `src/api/` | `app.py` â€” FastAPI factory, `routes.py` â€” endpoints, `schemas.py` â€” models |
| Core | `src/core/` | `chat.py` â€” chat service, `agent.py` â€” LangGraph ReAct agent, `tools.py` â€” tool registry |
| Common | `src/common/` | `config.py` â€” settings & model registry, `logger.py` â€” logging |
| Infra | `docker/` | Docker Compose (Ollama + LiteLLM) |

## Quick Start

### Prerequisites

- Python 3.10+
- Docker & Docker Compose *(for local models only)*
- NVIDIA GPU + drivers *(optional, for faster local inference)*
- Groq API key *(optional, for cloud models)*

### 1. Set up environment

```bash
git clone <repository-url>
cd chat
python -m venv .venv

# Windows
.venv\Scripts\activate
# Linux/macOS
source .venv/bin/activate

pip install -r requirements.txt
```

### 2. Configure

```bash
cp .env.example .env
# Edit .env â€” add your GROQ_API_KEY for cloud models
```

### 3. Start LLM infrastructure (optional â€” for local models)

```bash
cd docker
docker compose up -d
# Wait for models to download (~5â€“10 min first time)
docker compose logs -f model-puller
cd ..
```

### 4. Launch the app

```bash
# Terminal 1 â€” API backend
uvicorn src.api.app:app --reload

# Terminal 2 â€” Streamlit UI
streamlit run src/ui/chat.py
```

- **Chat UI:** `http://localhost:8501`
- **API docs:** `http://localhost:8000/docs`

## Available Models

| Model | Provider | ID | Notes |
|-------|----------|-----|-------|
| Phi-3 | Local | `phi3` | Default model, lightweight |
| Gemma 2B | Local | `gemma:2b` | Google's compact model |
| Mistral | Local | `mistral` | Strong general-purpose model |
| GPT-4 Turbo | Local | `gpt-4-turbo` | Mapped to Llama3 locally |
| Qwen3 4B | Local | `qwen3` | Alibaba's multilingual model |
| Groq GPT-OSS 120B | Groq | `openai/gpt-oss-120b` | Large cloud model |
| Groq Llama 3.1 70B | Groq | `llama-3.1-70b-versatile` | Fast cloud model |
| Groq Llama 3.1 8B | Groq | `llama-3.1-8b-instant` | Fastest cloud model |
| Groq Mixtral 8x7B | Groq | `mixtral-8x7b-32768` | MoE architecture |

## Project Structure

```
chat/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ common/              # Shared utilities
â”‚   â”‚   â”œâ”€â”€ config.py        # Env settings, model registry, model factory
â”‚   â”‚   â””â”€â”€ logger.py        # Rotating file + console logging
â”‚   â”œâ”€â”€ core/                # Business logic
â”‚   â”‚   â”œâ”€â”€ agent.py         # LangGraph ReAct agent + callback logger
â”‚   â”‚   â”œâ”€â”€ chat.py          # Public chat service interface
â”‚   â”‚   â””â”€â”€ tools.py         # Tool definitions (web search)
â”‚   â”œâ”€â”€ api/                 # FastAPI REST layer
â”‚   â”‚   â”œâ”€â”€ app.py           # Application factory + middleware
â”‚   â”‚   â”œâ”€â”€ routes.py        # Endpoint handlers
â”‚   â”‚   â””â”€â”€ schemas.py       # Request/response Pydantic models
â”‚   â””â”€â”€ ui/                  # Streamlit frontend
â”‚       â””â”€â”€ chat.py          # Chat UI (entry point)
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ config.yaml          # LiteLLM model routing
â”‚   â””â”€â”€ docker-compose.yml   # Ollama + LiteLLM services
â”œâ”€â”€ tests/                   # Test suite (empty â€” not yet implemented)
â”œâ”€â”€ docs/                    # Project documentation
â”œâ”€â”€ logs/                    # Log files (auto-created, git-ignored)
â”œâ”€â”€ .env.example             # Environment variable template
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md
```

## Environment Variables

| Variable | Default | Description |
|---|---|---|
| `OPENAI_ENDPOINT` | `http://localhost:4000/` | LiteLLM proxy URL |
| `OPENAI_API_KEY` | `my-secret-key` | LiteLLM API key |
| `GROQ_API_KEY` | *(empty)* | Groq cloud API key |
| `FASTAPI_URL` | `http://localhost:8000` | Backend URL for Streamlit |
| `LOG_LEVEL` | `INFO` | `DEBUG` / `INFO` / `WARNING` / `ERROR` |
| `LOG_FILE` | `logs/app.log` | Log file path |
| `LOG_MAX_MB` | `10` | Max log file size (MB) before rotation |
| `LOG_BACKUPS` | `5` | Number of rotated log backups |

## Adding a New Model

1. Add the model pull command in `docker/docker-compose.yml` â†’ `model-puller` service *(local only)*
2. Add model routing in `docker/config.yaml` â†’ `model_list` *(local only)*
3. Register display name + provider in `src/common/config.py` â†’ `AVAILABLE_MODELS`
4. Add the env var to `.env.example`

## Adding a New Tool

1. Define the tool in `src/core/tools.py`
2. Add it to the `ALL_TOOLS` list
3. The agent will automatically discover and use it when appropriate

## Documentation

Full project documentation is available in the [`docs/`](docs/) folder:

- [Documentation Index](docs/index.md)
- [Project Overview](docs/project-overview.md)
- [Architecture](docs/architecture.md)
- [Source Tree Analysis](docs/source-tree-analysis.md)
- [Development Guide](docs/development-guide.md)

## License

_No license specified._
